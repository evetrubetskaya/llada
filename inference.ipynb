{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483e7687-8bc1-4b3d-b45c-02e53d88e9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from model import DiT, CategoricalFlowMatching, SmallConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244ac4a7-67d3-4074-9fda-9cc6517b5c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df17be48-791f-4fa3-a2b1-475b1df68c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = SmallConfig()\n",
    "dit = DiT(config.dim, config.n_heads, config.dim_mult, config.n_layers, config.vocab_size)\n",
    "model = CategoricalFlowMatching(dit, config.vocab_size).to(torch.bfloat16).cuda().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f34b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"num parameters: {sum([p.numel() for p in model.parameters()])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d44299d-f19c-4e77-adba-12f8b7d938a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = torch.load('./logs/pretrain/latest.pt', map_location='cpu', weights_only=True)\n",
    "state_dict = {k.replace('._orig_mod', ''): v for k, v in d['model'].items()}\n",
    "model.load_state_dict(state_dict), d['iteration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e437c479",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [torch.LongTensor(tokenizer.encode('Moscow is the captital of Russia and'))]\n",
    "prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df57593-811a-496b-8356-7a077e40a837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(12345)\n",
    "with torch.amp.autocast('cuda', dtype=torch.bfloat16):\n",
    "    seqs, states = model.sample(1, T=1024, prompts=prompts, timesteps=128, temperature=0.9, verbose=True)\n",
    "\n",
    "for text in [tokenizer.decode(seq) for seq in seqs]:\n",
    "    print(text)\n",
    "    print('--------------------------------------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1709d6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the evolution of text generation\n",
    "\n",
    "idx = 0\n",
    "\n",
    "progress = [tokenizer.decode(state[idx].cpu().tolist()).replace('<|endoftext|>', '') for state in states]\n",
    "\n",
    "for i in [-1, -2, -3, -4, -5, -len(states)//3, -len(states)//2, 0]:\n",
    "    print(f'[{i}, {len(progress[i])}]:', progress[i])\n",
    "    print('-------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a828124a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
